{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3bf8dd-e691-45a7-9166-545cf85d822a",
   "metadata": {},
   "source": [
    "## Assignment 2: Predicting Health Impacts from Air Quality Factors\n",
    "In this assignment, we will use a (synthetic) data set looking at how health impacts are related to air quality factors. This data set is available at [https://www.kaggle.com/datasets/rabieelkharoua/air-quality-and-health-impact-dataset](https://www.kaggle.com/datasets/rabieelkharoua/air-quality-and-health-impact-dataset). The data includes public health outcomes and how they are related to air quality and meteorological factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9501c7-7cc0-4c2f-ab52-8b144e798237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fdc75-fa1c-475a-a2a1-801514a60a8e",
   "metadata": {},
   "source": [
    "## Download the data from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc061431-d007-4144-8f73-b5289ab28ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (0.2.9)\r\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from kagglehub) (24.1)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from kagglehub) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from kagglehub) (4.66.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from requests->kagglehub) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from requests->kagglehub) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from requests->kagglehub) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from requests->kagglehub) (2024.8.30)\r\n"
     ]
    }
   ],
   "source": [
    "# To facilitate downloading data from Kaggle, we can install this python package\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bc012d-ff39-427d-b726-ef510e341e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/karalamb/.cache/kagglehub/datasets/rabieelkharoua/air-quality-and-health-impact-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rabieelkharoua/air-quality-and-health-impact-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b49dabbe-6650-43bb-87a1-37867bf79f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_quality_health_impact_data.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8efac-fa24-4703-80b4-83663591af12",
   "metadata": {},
   "source": [
    "## Part 1: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307131e4-69ab-4ec0-9db5-0763cb735772",
   "metadata": {},
   "source": [
    "1. Load in the csv file as a dataframe using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04ce8a44-cf78-45ed-b01a-8778f02ea642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252ca2f-9859-4091-ba5d-b9f2d35070bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82538323-5668-4009-9ed3-6ec540c56445",
   "metadata": {},
   "source": [
    "2. Check whether there are any NaN's in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80ca66-d8e9-48b4-8736-43762a4575e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5fc23f-0227-424a-95aa-55d69c64112f",
   "metadata": {},
   "source": [
    "3. Make a histogram of the different numerical variables in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26804cad-bf4e-4b2c-97f9-f5d5831b34ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17542c3b-e834-46b8-bcf9-c01cdf472743",
   "metadata": {},
   "source": [
    "4. There are two possible targets in the dataframe. One is a categorical variable `HealthImpactClass`, and the other is a numerical variable `HealthImpactScore`. Create numpy arrays, one named `y_classification`, containing the `HealthImpactClass`, and one named `y_regression`, containing the `HealthImpactScore`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51889a43-999c-4f5b-920a-07bb7cb93956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05eded-36ca-4d1a-9075-4e14e375fe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633b0a3a-1953-4971-9e5b-612857f1c8b5",
   "metadata": {},
   "source": [
    "5. Check how balanced the 5 classes are in `HealthImpactClass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a78cd-a946-4030-b667-b7522412a6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed67401-6af7-4894-bc22-a596ceff1f91",
   "metadata": {},
   "source": [
    "6. Create a numpy array called `features` that includes the following 9 variables:\n",
    "   - AQI\n",
    "   - PM10\n",
    "   - PM2_5\n",
    "   - NO2\n",
    "   - SO2\n",
    "   - O3\n",
    "   - Temperature\n",
    "   - Humidity\n",
    "   - WindSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0b178-9788-4e01-aed9-b494f5b5dc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67003dcf-5a93-446f-8590-cde80c6fc3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d236d878-696f-4d1b-92ef-8198c180ff0b",
   "metadata": {},
   "source": [
    "## Part 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a1c23-16da-4870-98c7-9fb077a3f1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b84c28d-d009-4ad2-93da-ca6a9f89ca63",
   "metadata": {},
   "source": [
    "7. Create two python lists, one including the class names, and the other including the feature names. The classification of health impact is derived from the health impact score, using the following thresholds:\n",
    "- 0: 'Very High' (HealthImpactScore >= 80)\n",
    "- 1: 'High' (60 <= HealthImpactScore < 80)\n",
    "- 2: 'Moderate' (40 <= HealthImpactScore < 60)\n",
    "- 3: 'Low' (20 <= HealthImpactScore < 40)\n",
    "- 4: 'Very Low' (HealthImpactScore < 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8fa8d-ad21-4661-b5f1-8455e98e4068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed641e-0f9f-48b3-b33f-fa05e956d60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed05a37-81b7-49a4-8376-2ef78ee8011e",
   "metadata": {},
   "source": [
    "8. Use the `StandardScaler` method to scale the numerical variables in the `feature` array, and save this as a numpy array `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc8efd-7104-4068-96b1-e60557b3dbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ed0d4-4388-4fc5-92be-a82bbfb19d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb305fa-f020-4f7b-ac43-f85d503214d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f2a56-6d20-42b5-a5d1-42d6f20ec82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d20b1c1-58e0-4a55-9a96-42a1dab6b330",
   "metadata": {},
   "source": [
    "## Part 3: Training, validation, and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6cc40b-89dc-4b45-a762-a7640edaa069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa589a46-d5a4-49fd-9848-06fdb9936bf7",
   "metadata": {},
   "source": [
    "9. Split the data into training, validation, and test data sets, with 80% of the data used for training, and 10% each for validation and testing. Create separate regression and classification targets, using `y_classification` and `y_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f31a7f-c0e8-4196-9847-c806c5e419eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bf80b-3aeb-49a4-830d-d1fc03dd63cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347af1c0-8e50-4bd6-b4c1-c65063ed0b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce77a5-77a6-4ed8-96bb-a6b1d28d3bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20c47604-dfe8-4ca7-9b9d-014871c476bf",
   "metadata": {},
   "source": [
    "## Part 4: Train a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75164a-6b17-48d4-bffc-141d3e9f580f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea789ac-79a6-4ec2-82d7-d73b0facba2e",
   "metadata": {},
   "source": [
    "10. Train a `RandomForestClassifier` with 120 estimators and with a maximum depth of 10. Set the class_weight to \"balanced\", since the classes are imbalanced. You can use the default values for other hyperparmameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b3069-4138-43fe-be25-d954f0cb16d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbbdc55-5186-4ea5-a17a-578dd36c498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34760dd-24d4-4a10-abee-5c80a65723da",
   "metadata": {},
   "source": [
    "11. Create a heatmap plot for the confusion matrix showing the performance of the trained classifier on the validation data set. Label the heatmap with the `classnames` on the x and y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db3204-c95e-4b81-a455-c8661eefe7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8eef81-a2ff-484d-96b3-424a9dfdc57a",
   "metadata": {},
   "source": [
    "Because the classes are imbalanced, the confusion matrix shows that the classifier does not perform that well on the classes that are not well-represented in the data. One way to improve this is to use over-sampling to augment the data set. Using the `imbalanced-learn` library, we can use the `SMOTE` algorithm [(https://arxiv.org/pdf/1106.1813)](https://arxiv.org/pdf/1106.1813) to oversample the data set, using the lines of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50da6ee-311e-4bbd-ad69-abc81e895401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (0.12.4)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from imbalanced-learn) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from imbalanced-learn) (1.10.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from imbalanced-learn) (1.3.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from imbalanced-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/ML4Climate2025/lib/python3.8/site-packages (from imbalanced-learn) (3.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694f0508-0bae-4c61-b089-04524b03abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c44780-2425-4dae-8e6f-6708ab9ba773",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m SMOTE()\u001b[38;5;241m.\u001b[39mfit_resample(\u001b[43mX_train\u001b[49m, y_classification_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_classification_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9591250-3494-4651-8a83-68a4b8b7e342",
   "metadata": {},
   "source": [
    "12. Train a new random forest classifier using `X_resampled` and `y_resampled`. Use the same hyperparameters as your original random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf0657-100a-475b-aa56-4f480134d5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15f44b-56b0-4630-a237-d1632f15b0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e72117-8329-4a29-8c37-15be8ff03bd4",
   "metadata": {},
   "source": [
    "13. Create a new heatmap plot for the confusion matrix showing the performance of the classifier that was trained on the oversampled data set, evaluated on the validation data set. Label the heatmap with the `classnames` list on the x and y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6bc85d-f0d3-49ac-93cb-0b84b7820727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85458b7-8092-4222-9534-90823fc499ca",
   "metadata": {},
   "source": [
    "## Part 5: Train a Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b8f94-e2b9-42b4-9397-558021def8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca5b2071-9647-49ee-aa14-42de905c636e",
   "metadata": {},
   "source": [
    "14. Train a `RandomForestRegressor` on the training data set, using the regression target. Set the number of estimators to 120 and the maximum tree depth to 10. You can use the other default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c343f-a2ae-4d9b-a7c6-a2c8a2594047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90799e2f-1045-4f79-a20d-cd7311963d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a8fca9-b53a-4e9f-8daa-ba9aed8eba49",
   "metadata": {},
   "source": [
    "15. Using your trained `RandomForestRegressor`, predict the target values for the validation data set and calculate the coefficient of determination between the true targets and the values predicted by the `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0c4e6-b005-4393-abed-c2112d41426a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ef89-9063-479f-a63e-799a10f1af45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed22bc-7f07-47a4-814d-0481ad4215a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0ac7460-1d73-4bb2-9c51-2ecaca1026ef",
   "metadata": {},
   "source": [
    "16. Make a barplot of the feature importance in your trained random forest. Label the x-axis with the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b355a13-2b25-4e13-b729-1340123f2dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7af0e1c9-41a8-43c1-bef0-6106bb5c82c7",
   "metadata": {},
   "source": [
    "17.  What are the 4 most important features in terms of determining the health impact score? Print them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d9b60-e279-49d3-9734-4fde9cb14159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7291410-d314-4f90-b8ec-2f1206293836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}